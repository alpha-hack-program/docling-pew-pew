{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207cabea-3628-47f4-b8c7-6aee270b86aa",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd17b00-6a55-49ad-a8bc-190988143593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install requests docling transformers ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795ccba-4313-40b9-ab56-aa89f286629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus llama-index-readers-file python-dotenv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff599941-1a81-4f9d-8e83-f9c53f443039",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Docling and chunker for text parsing\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "## embeddings generator\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3ac39-ed1c-46f0-b5d1-6c38431e0b86",
   "metadata": {},
   "source": [
    "# Docling ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516035be-907d-4659-9fe8-dcb1bc5c657f",
   "metadata": {},
   "source": [
    "## Define global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a0587e-56e9-44cf-bcfa-64f167e0713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source for the documents for docling parsing of chunks\n",
    "source_file = \"http://minio-ui-ic-shared-minio.apps.ocp.sandbox2941.opentlc.com/api/v1/download-shared-object/aHR0cDovLzEyNy4wLjAuMTo5MDAwL3BkZnMvUmVkX0hhdF9PcGVuU2hpZnRfQUlfU2VsZi1NYW5hZ2VkLTIuMTYtR2V0dGluZ19zdGFydGVkX3dpdGhfUmVkX0hhdF9PcGVuU2hpZnRfQUlfU2VsZi1NYW5hZ2VkLWVuLVVTLnBkZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUVNWURIR0pFNDBQQzczVElMWVBFJTJGMjAyNTAxMTQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTE0VDE0MTIxNFomWC1BbXotRXhwaXJlcz00MzIwMCZYLUFtei1TZWN1cml0eS1Ub2tlbj1leUpoYkdjaU9pSklVelV4TWlJc0luUjVjQ0k2SWtwWFZDSjkuZXlKaFkyTmxjM05MWlhraU9pSkZUVmxFU0VkS1JUUXdVRU0zTTFSSlRGbFFSU0lzSW1WNGNDSTZNVGN6Tmprd056QTNPQ3dpY0dGeVpXNTBJam9pYldsdWFXOGlmUS53c2NjZ3dCSVdoYl92UFBYMmlyZUZxVHh4MzZyN18xX3JKcXZLUUcxWVhJXzh1TXBKQUxzb0xkRWU3VXBROE5lWHFtdzNRX1ppU1duUDdXSzJ0SlFYdyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmdmVyc2lvbklkPW51bGwmWC1BbXotU2lnbmF0dXJlPWY1MDBmNDc4MThhYzE3YjU4NmQ5YmU4ZTkyMzI3OTQ0ZDlhNmQ5YWFiNDU1ZjI4ZmQzM2I3ODVmYTc0NjliZDA\"  # document per local path or URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6664e81-e172-4255-b296-3f4ae8b05442",
   "metadata": {},
   "source": [
    "## 0) Ingest documentation - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9131a61-d282-4a7f-9727-fb46a6d29479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "\n",
      "## Red Hat OpenShift AI Self-Managed 2.16\n",
      "\n",
      "## Getting started with Red Hat OpenShift AI Self-Managed\n",
      "\n",
      "Learn how to work in an OpenShift AI environment\n",
      "\n",
      "## Red Hat OpenShift AI Self-Managed 2.16 Getting started with Red Hat OpenShift AI Self-Managed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Define Converter\n",
    "converter = DocumentConverter()\n",
    "\n",
    "## Parse document from source and store in variable \"document\"\n",
    "document = converter.convert(source_file)\n",
    "\n",
    "\n",
    "## Print to check everything is working\n",
    "# print(document.document.export_to_markdown())\n",
    "lines = document.document.export_to_markdown().splitlines()\n",
    "for line in lines[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc64833-10bd-4eb9-a769-754735d87695",
   "metadata": {},
   "source": [
    "## 1) Chunking the downloaded document using Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a21665-166f-476c-b91d-59d960dc140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn how to work in an OpenShift AI environment\n",
      "Last Updated: 2024-12-11\n"
     ]
    }
   ],
   "source": [
    "## Parse document from source and store in variable \"document\"\n",
    "converted_source_file = DocumentConverter().convert(source_file)\n",
    "document = converted_source_file.document\n",
    "\n",
    "## Create chubker and chuck document\n",
    "chunker = HybridChunker(tokenizer=\"BAAI/bge-small-en-v1.5\")  # set tokenizer as needed\n",
    "chunk_iter = chunker.chunk(document)\n",
    "\n",
    "## Create chunk_list with the parts of the document\n",
    "chunk_list = list(chunk_iter)\n",
    "\n",
    "#for i,chunk in enumerate(chunk_iter):\n",
    "    #print(i)\n",
    "    #print(chunk)\n",
    "\n",
    "## Print to check everything is working\n",
    "# print(chunk_list[0])\n",
    "print(chunk_list[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2cd433-ae4f-4976-9f8e-751295941edf",
   "metadata": {},
   "source": [
    "## 2) Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa57f12d-eba4-4c8f-90c0-fdf8972788a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Vector: 47\n"
     ]
    }
   ],
   "source": [
    "## Defined embedding model and import it\n",
    "embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "## Define Empty Vector Array\n",
    "vectors = []\n",
    "## Populate Vector Array\n",
    "for i, chunk in enumerate(chunk_list):\n",
    "    vectors.append({\n",
    "        \"id\": i, \n",
    "        \"vector\": embedding_model.get_text_embedding(chunk.text) , \n",
    "        \"text\": chunk.text\n",
    "    })\n",
    "\n",
    "## Print to check everything is working\n",
    "print(f'Length of the Vector: {len(vectors)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081006d5-5816-45ec-8dd3-ca4a617094ac",
   "metadata": {},
   "source": [
    "## 3) Upload embeddings to Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa4fb92-b64d-464c-a33d-072367f5187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "## Connect to Milvus (adjust host/port as needed)\n",
    "connections.connect(\"default\", \n",
    "    host=\"vectordb-milvus.milvus.svc.cluster.local\", \n",
    "    port=\"19530\",\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "\n",
    "## Define a collection schema (adjust dimensions based on your embedding size)\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=len(vectors[0][\"vector\"])),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65000),\n",
    "    ## TODO: Add version\n",
    "    #    FieldSchema(name=\"version\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "]\n",
    "schema = CollectionSchema(fields, description=\"RAG embeddings collection\")\n",
    "\n",
    "## TODO: search\n",
    "# res = client.search(\n",
    "#     collection_name=\"my_collection\",\n",
    "#     data=[query_vector],\n",
    "#     limit=5,\n",
    "#     # highlight-start\n",
    "#     filter='color like \"red%\" and likes > 50',\n",
    "#     output_fields=[\"color\", \"likes\"]\n",
    "#     # highlight-end\n",
    "# )\n",
    "\n",
    "\n",
    "## Create or load a collection\n",
    "collection_name = \"rag_embeddings\"\n",
    "collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "## TODO: Create an index for faster similarity search\n",
    "index_params = {\"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", \"params\": {\"nlist\": len(vectors[0][\"vector\"])}}\n",
    "collection.create_index(field_name=\"vector\", index_params=index_params)\n",
    "\n",
    "## Load the collection for querying\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a285316-edb3-495b-be97-9ee02d218f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(insert count: 47, delete count: 0, upsert count: 0, timestamp: 455311954974343175, success count: 47, err count: 0\n"
     ]
    }
   ],
   "source": [
    "## Insert vectors into Milvus\n",
    "insert_output = collection.insert(vectors);\n",
    "\n",
    "## Print to check everything is working\n",
    "print(insert_output)\n",
    "\n",
    "## Load the collection for querying\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc3a4f-464d-4204-9d91-37655d580259",
   "metadata": {},
   "source": [
    "## 3) Query the Database to obtain RAG parsed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b832f0f-9dd1-4543-be58-fe91395c479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87120d0-5629-4a72-b371-1db8bf32b42a",
   "metadata": {},
   "source": [
    "## 4) Query Mistral Using RAG information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c976f4-bdc0-4034-bac0-fdf036d47658",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'markdown_dummy_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are a commentator. Your task is to write a report on an essay.\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mWhen presented with the essay, come up with interesting questions to ask, and answer each question.\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mAfterward, combine all the information and write a report in the markdown format.\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m# Essay:\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmarkdown_dummy_2\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m# Instructions:\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m## Summarize:\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mIn clear and concise language, summarize the key points and themes presented in the essay.\u001b[39m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m## Interesting Questions:\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mGenerate three distinct and thought-provoking questions that can be asked about the content of the essay. For each question:\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m- After \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, describe the problem\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m- After \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, provide a detailed explanation of the problem addressed in the question.\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m- Enclose the ultimate answer in <>.\u001b[39m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m## Write a report\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124mUsing the essay summary and the answers to the interesting questions, create a comprehensive report in Markdown format.\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'markdown_dummy_2' is not defined"
     ]
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "You are a commentator. Your task is to write a report on an essay.\n",
    "When presented with the essay, come up with interesting questions to ask, and answer each question.\n",
    "Afterward, combine all the information and write a report in the markdown format.\n",
    "\n",
    "# Essay:\n",
    "{markdown_dummy_2}\n",
    "\n",
    "# Instructions:\n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes presented in the essay.\n",
    "\n",
    "## Interesting Questions:\n",
    "Generate three distinct and thought-provoking questions that can be asked about the content of the essay. For each question:\n",
    "- After \"Q: \", describe the problem\n",
    "- After \"A: \", provide a detailed explanation of the problem addressed in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "\n",
    "## Write a report\n",
    "Using the essay summary and the answers to the interesting questions, create a comprehensive report in Markdown format.\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
